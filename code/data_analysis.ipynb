{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54c77316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192 200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'conversation_id': '930-b01cb51d-748d-460c-841a-08e4d5cd5cc7',\n",
       " 'conversation_history': 'Tutor: Hi, could you please provide a step-by-step solution for the question below? The question is: Elliott is trying to walk 10,000 steps a day. He finished half of his steps on his walks to and from school and did another 1,000 steps going for a short walk with his friend. He also went for a short jog around the block and realized that after he had finished his jog, he only had 2,000 steps left to take. How many steps did Elliott take during his jog?\\xa0\\n\\xa0Student: Elliott finished half of his steps on his walks to and from school, so he took 10,000/2 = 5000 steps during these walks.\\nAdding the 1,000 steps he took with his friend, he has taken 5000+1000 = 6000 steps.\\nSubtracting 6000 from his goal of 10,000, he has 10,000-6000 = 4000 steps left to take.\\nTherefore, he took 4000 steps during his jog.\\xa0\\n\\xa04000\\xa0\\n\\xa0Tutor: can you tell me how you got to your answer?\\xa0\\n\\xa0Student: Sure. I started by figuring out how many steps Elliott had taken before his jog. I knew he had finished half of his steps on his walks to and from school so I calculated that he had taken 10000/2 = 5000 steps during these walks. Then I added the 1000 steps he took with his friend so I had taken 5000+1000 = 6000 steps. After that I subtracted 6000 from his goal of 10000 so I had 10000-6000 = 4000 steps left to take. This meant that he had taken 4000 steps during his jog.',\n",
       " 'Data': 'MathDial',\n",
       " 'Split': 'test',\n",
       " 'Topic': 'Not Available',\n",
       " 'Ground_Truth_Solution': 'Elliott took half of his steps on his school journey, which was 10,000 steps / 2 = 5,000 steps.\\nAdding this to his short walk means he has taken 5,000 + 1,000 = 6,000 steps.\\nHe only has 2,000 steps left, which means that during the day, he has taken 10,000 goal steps – 2,000 remaining steps = 8,000 steps.\\nThe difference between these is therefore the steps he took during his jog, which was 8,000 total steps – 6,000 steps on his school walks and short walks = 2,000 steps.\\n 2000',\n",
       " 'anno_llm_responses': {'Gemini': {'response': \"It looks like you're on the right track, but remember that Elliott still had 2,000 steps left to take *after* his jog.\",\n",
       "   'annotation': {'Mistake_Identification': 'Yes',\n",
       "    'Mistake_Location': 'Yes',\n",
       "    'Revealing_of_the_Answer': 'No',\n",
       "    'Providing_Guidance': 'Yes',\n",
       "    'Actionability': 'Yes',\n",
       "    'humanlikeness': 'Yes',\n",
       "    'Coherence': 'Yes',\n",
       "    'Tutor_Tone': 'Neutral'}},\n",
       "  'Phi3': {'response': \"Great job! To further enhance your understanding, let's explore more examples and practice solving similar problems together.\",\n",
       "   'annotation': {'Mistake_Identification': 'No',\n",
       "    'Mistake_Location': 'No',\n",
       "    'Revealing_of_the_Answer': 'No',\n",
       "    'Providing_Guidance': 'No',\n",
       "    'Actionability': 'No',\n",
       "    'humanlikeness': 'Yes',\n",
       "    'Coherence': 'No',\n",
       "    'Tutor_Tone': 'Encouraging'}},\n",
       "  'Llama318B': {'response': \"That's a good attempt, but I'm not seeing how you factored in the remaining 2000 steps Elliott had left after his jog into your calculation - could you show me how you think those steps fit into the equation?\",\n",
       "   'annotation': {'Mistake_Identification': 'Yes',\n",
       "    'Mistake_Location': 'Yes',\n",
       "    'Revealing_of_the_Answer': 'No',\n",
       "    'Providing_Guidance': 'Yes',\n",
       "    'Actionability': 'Yes',\n",
       "    'humanlikeness': 'Yes',\n",
       "    'Coherence': 'Yes',\n",
       "    'Tutor_Tone': 'Encouraging'}},\n",
       "  'Llama31405B': {'response': 'Here\\'s a tutor response that acknowledges the student\\'s effort and encourages them to revisit their thinking:\\n\\n\"I see that you\\'ve carefully calculated the steps Elliott took before his jog, but I\\'m wondering if you considered the fact that he only had 2,000 steps left to take after his jog, which might affect the number of steps he took during the jog itself?\"',\n",
       "   'annotation': {'Mistake_Identification': 'Yes',\n",
       "    'Mistake_Location': 'Yes',\n",
       "    'Revealing_of_the_Answer': 'No',\n",
       "    'Providing_Guidance': 'Yes',\n",
       "    'Actionability': 'Yes',\n",
       "    'humanlikeness': 'No',\n",
       "    'Coherence': 'Yes',\n",
       "    'Tutor_Tone': 'Neutral'}},\n",
       "  'Mistral': {'response': 'It seems like you forgot to consider the 2,000 steps Elliott still had left after his jog.',\n",
       "   'annotation': {'Mistake_Identification': 'Yes',\n",
       "    'Mistake_Location': 'Yes',\n",
       "    'Revealing_of_the_Answer': 'No',\n",
       "    'Providing_Guidance': 'Yes',\n",
       "    'Actionability': 'Yes',\n",
       "    'humanlikeness': 'Yes',\n",
       "    'Coherence': 'Yes',\n",
       "    'Tutor_Tone': 'Neutral'}},\n",
       "  'Expert': {'response': 'But after his jog he still had 2000 steps left',\n",
       "   'annotation': {'Mistake_Identification': 'Yes',\n",
       "    'Mistake_Location': 'Yes',\n",
       "    'Revealing_of_the_Answer': 'No',\n",
       "    'Providing_Guidance': 'Yes',\n",
       "    'Actionability': 'Yes',\n",
       "    'humanlikeness': 'Yes',\n",
       "    'Coherence': 'Yes',\n",
       "    'Tutor_Tone': 'Neutral'}},\n",
       "  'GPT4': {'response': \"I see where your confusion is. You subtracted the total steps he had already taken from his goal, but the problem states that after his jog, Elliott had 2,000 steps left, which means he must have done 2,000 steps during his jog, not 4,000. Let's try to recalculate it together.\",\n",
       "   'annotation': {'Mistake_Identification': 'Yes',\n",
       "    'Mistake_Location': 'Yes',\n",
       "    'Revealing_of_the_Answer': 'Yes (and the answer is correct)',\n",
       "    'Providing_Guidance': 'Yes',\n",
       "    'Actionability': 'No',\n",
       "    'humanlikeness': 'Yes',\n",
       "    'Coherence': 'Yes',\n",
       "    'Tutor_Tone': 'Encouraging'}},\n",
       "  'Sonnet': {'response': \"Great job showing your work, but let's take another look at the last part of the problem statement to make sure we're considering all the information given.\",\n",
       "   'annotation': {'Mistake_Identification': 'To some extent',\n",
       "    'Mistake_Location': 'No',\n",
       "    'Revealing_of_the_Answer': 'No',\n",
       "    'Providing_Guidance': 'To some extent',\n",
       "    'Actionability': 'To some extent',\n",
       "    'humanlikeness': 'Yes',\n",
       "    'Coherence': 'To some extent',\n",
       "    'Tutor_Tone': 'Encouraging'}}}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json, os\n",
    "root_dir = \"../data\"\n",
    "MRBenchv1 = os.path.join(root_dir, \"MRBench/MRBench_V1.json\")\n",
    "MRBenchv2 = os.path.join(root_dir, \"MRBench/MRBench_V2.json\")\n",
    "\n",
    "MRBenchv1_data = json.load(open(MRBenchv1))\n",
    "MRBenchv2_data = json.load(open(MRBenchv2))\n",
    "print(len(MRBenchv1_data), len(MRBenchv2_data))\n",
    "MRBenchv1_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6cadca",
   "metadata": {},
   "source": [
    "MRBench_V1: The original dataset with 192 dialogues as deatiled in the paper.\n",
    "\n",
    "MRBench_V2: An updated version with additional 8 dialogues, bringing the total to 200 examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5227024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conversation_id': '930-b01cb51d-748d-460c-841a-08e4d5cd5cc7', 'conversation_history': 'Tutor: Hi, could you please provide a step-by-step solution for the question below? The question is: Elliott is trying to walk 10,000 steps a day. He finished half of his steps on his walks to and from school and did another 1,000 steps going for a short walk with his friend. He also went for a short jog around the block and realized that after he had finished his jog, he only had 2,000 steps left to take. How many steps did Elliott take during his jog?\\xa0\\n\\xa0Student: Elliott finished half of his steps on his walks to and from school, so he took 10,000/2 = 5000 steps during these walks.\\nAdding the 1,000 steps he took with his friend, he has taken 5000+1000 = 6000 steps.\\nSubtracting 6000 from his goal of 10,000, he has 10,000-6000 = 4000 steps left to take.\\nTherefore, he took 4000 steps during his jog.\\xa0\\n\\xa04000\\xa0\\n\\xa0Tutor: can you tell me how you got to your answer?\\xa0\\n\\xa0Student: Sure. I started by figuring out how many steps Elliott had taken before his jog. I knew he had finished half of his steps on his walks to and from school so I calculated that he had taken 10000/2 = 5000 steps during these walks. Then I added the 1000 steps he took with his friend so I had taken 5000+1000 = 6000 steps. After that I subtracted 6000 from his goal of 10000 so I had 10000-6000 = 4000 steps left to take. This meant that he had taken 4000 steps during his jog.', 'Data': 'MathDial', 'Split': 'test', 'Topic': 'Not Available', 'Ground_Truth_Solution': 'Elliott took half of his steps on his school journey, which was 10,000 steps / 2 = 5,000 steps.\\nAdding this to his short walk means he has taken 5,000 + 1,000 = 6,000 steps.\\nHe only has 2,000 steps left, which means that during the day, he has taken 10,000 goal steps – 2,000 remaining steps = 8,000 steps.\\nThe difference between these is therefore the steps he took during his jog, which was 8,000 total steps – 6,000 steps on his school walks and short walks = 2,000 steps.\\n 2000', 'anno_llm_responses': {'Gemini': {'response': \"It looks like you're on the right track, but remember that Elliott still had 2,000 steps left to take *after* his jog.\", 'annotation': {'Mistake_Identification': 'Yes', 'Mistake_Location': 'Yes', 'Revealing_of_the_Answer': 'No', 'Providing_Guidance': 'Yes', 'Actionability': 'Yes', 'humanlikeness': 'Yes', 'Coherence': 'Yes', 'Tutor_Tone': 'Neutral'}, 'annotation_point': {'Mistake_Identification': 1, 'Mistake_Location': 1, 'Revealing_of_the_Answer': 3, 'Providing_Guidance': 1, 'Actionability': 1, 'humanlikeness': 1, 'Coherence': 1, 'Tutor_Tone': 2}}, 'Phi3': {'response': \"Great job! To further enhance your understanding, let's explore more examples and practice solving similar problems together.\", 'annotation': {'Mistake_Identification': 'No', 'Mistake_Location': 'No', 'Revealing_of_the_Answer': 'No', 'Providing_Guidance': 'No', 'Actionability': 'No', 'humanlikeness': 'Yes', 'Coherence': 'No', 'Tutor_Tone': 'Encouraging'}, 'annotation_point': {'Mistake_Identification': 3, 'Mistake_Location': 3, 'Revealing_of_the_Answer': 3, 'Providing_Guidance': 3, 'Actionability': 3, 'humanlikeness': 1, 'Coherence': 3, 'Tutor_Tone': 1}}, 'Llama318B': {'response': \"That's a good attempt, but I'm not seeing how you factored in the remaining 2000 steps Elliott had left after his jog into your calculation - could you show me how you think those steps fit into the equation?\", 'annotation': {'Mistake_Identification': 'Yes', 'Mistake_Location': 'Yes', 'Revealing_of_the_Answer': 'No', 'Providing_Guidance': 'Yes', 'Actionability': 'Yes', 'humanlikeness': 'Yes', 'Coherence': 'Yes', 'Tutor_Tone': 'Encouraging'}, 'annotation_point': {'Mistake_Identification': 1, 'Mistake_Location': 1, 'Revealing_of_the_Answer': 3, 'Providing_Guidance': 1, 'Actionability': 1, 'humanlikeness': 1, 'Coherence': 1, 'Tutor_Tone': 1}}, 'Llama31405B': {'response': 'Here\\'s a tutor response that acknowledges the student\\'s effort and encourages them to revisit their thinking:\\n\\n\"I see that you\\'ve carefully calculated the steps Elliott took before his jog, but I\\'m wondering if you considered the fact that he only had 2,000 steps left to take after his jog, which might affect the number of steps he took during the jog itself?\"', 'annotation': {'Mistake_Identification': 'Yes', 'Mistake_Location': 'Yes', 'Revealing_of_the_Answer': 'No', 'Providing_Guidance': 'Yes', 'Actionability': 'Yes', 'humanlikeness': 'No', 'Coherence': 'Yes', 'Tutor_Tone': 'Neutral'}, 'annotation_point': {'Mistake_Identification': 1, 'Mistake_Location': 1, 'Revealing_of_the_Answer': 3, 'Providing_Guidance': 1, 'Actionability': 1, 'humanlikeness': 3, 'Coherence': 1, 'Tutor_Tone': 2}}, 'Mistral': {'response': 'It seems like you forgot to consider the 2,000 steps Elliott still had left after his jog.', 'annotation': {'Mistake_Identification': 'Yes', 'Mistake_Location': 'Yes', 'Revealing_of_the_Answer': 'No', 'Providing_Guidance': 'Yes', 'Actionability': 'Yes', 'humanlikeness': 'Yes', 'Coherence': 'Yes', 'Tutor_Tone': 'Neutral'}, 'annotation_point': {'Mistake_Identification': 1, 'Mistake_Location': 1, 'Revealing_of_the_Answer': 3, 'Providing_Guidance': 1, 'Actionability': 1, 'humanlikeness': 1, 'Coherence': 1, 'Tutor_Tone': 2}}, 'Expert': {'response': 'But after his jog he still had 2000 steps left', 'annotation': {'Mistake_Identification': 'Yes', 'Mistake_Location': 'Yes', 'Revealing_of_the_Answer': 'No', 'Providing_Guidance': 'Yes', 'Actionability': 'Yes', 'humanlikeness': 'Yes', 'Coherence': 'Yes', 'Tutor_Tone': 'Neutral'}, 'annotation_point': {'Mistake_Identification': 1, 'Mistake_Location': 1, 'Revealing_of_the_Answer': 3, 'Providing_Guidance': 1, 'Actionability': 1, 'humanlikeness': 1, 'Coherence': 1, 'Tutor_Tone': 2}}, 'GPT4': {'response': \"I see where your confusion is. You subtracted the total steps he had already taken from his goal, but the problem states that after his jog, Elliott had 2,000 steps left, which means he must have done 2,000 steps during his jog, not 4,000. Let's try to recalculate it together.\", 'annotation': {'Mistake_Identification': 'Yes', 'Mistake_Location': 'Yes', 'Revealing_of_the_Answer': 'Yes (and the answer is correct)', 'Providing_Guidance': 'Yes', 'Actionability': 'No', 'humanlikeness': 'Yes', 'Coherence': 'Yes', 'Tutor_Tone': 'Encouraging'}, 'annotation_point': {'Mistake_Identification': 1, 'Mistake_Location': 1, 'Revealing_of_the_Answer': 1, 'Providing_Guidance': 1, 'Actionability': 3, 'humanlikeness': 1, 'Coherence': 1, 'Tutor_Tone': 1}}, 'Sonnet': {'response': \"Great job showing your work, but let's take another look at the last part of the problem statement to make sure we're considering all the information given.\", 'annotation': {'Mistake_Identification': 'To some extent', 'Mistake_Location': 'No', 'Revealing_of_the_Answer': 'No', 'Providing_Guidance': 'To some extent', 'Actionability': 'To some extent', 'humanlikeness': 'Yes', 'Coherence': 'To some extent', 'Tutor_Tone': 'Encouraging'}, 'annotation_point': {'Mistake_Identification': 2, 'Mistake_Location': 3, 'Revealing_of_the_Answer': 3, 'Providing_Guidance': 2, 'Actionability': 2, 'humanlikeness': 1, 'Coherence': 2, 'Tutor_Tone': 1}}}}\n"
     ]
    }
   ],
   "source": [
    "def map_annotation_label(key, label):\n",
    "    Tutor_tone_mapping = {\n",
    "        \"encouraging\": 1,\n",
    "        \"neutral\": 2,\n",
    "        \"offensive\": 3\n",
    "    }\n",
    "    Other_rule_mapping = {\n",
    "        \"yes\": 1,\n",
    "        \"to some extent\": 2,\n",
    "        \"no\": 3\n",
    "    }\n",
    "    map_dict = Tutor_tone_mapping if key == \"Tutor_Tone\" else Other_rule_mapping\n",
    "    for key, value in map_dict.items():\n",
    "        # if key in label.lower():\n",
    "        #     return value\n",
    "        if label.lower().startswith(key):\n",
    "            return value\n",
    "    print(label)\n",
    "    return None\n",
    "    \n",
    "    \n",
    "MRBenchv1_data_mapped = []\n",
    "for data in MRBenchv1_data:\n",
    "    for key, value in data['anno_llm_responses'].items():\n",
    "        annotation = value['annotation']\n",
    "        new_annotation = {}\n",
    "        for k, v in annotation.items():\n",
    "            new_annotation[k] = map_annotation_label(k,v)\n",
    "        value['annotation_point'] = new_annotation\n",
    "    MRBenchv1_data_mapped.append(data)\n",
    "print(MRBenchv1_data_mapped[0])\n",
    "    \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f05fb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "desiderata = {\n",
    "    \"Mistake_Identification\": 1,  # Yes\n",
    "    \"Mistake_Location\": 1,        # Yes\n",
    "    \"Revealing_of_the_Answer\": 3,        # No\n",
    "    \"Providing_Guidance\": 1,      # Yes\n",
    "    \"Actionability\": 1,           # Yes\n",
    "    \"Coherence\": 1,                # Yes\n",
    "    \"Tutor_Tone\": 1,              # Encouraging\n",
    "    \"humanlikeness\": 1,               # Yes\n",
    "}\n",
    "\n",
    "# new_annotation\n",
    "def evaluate_ordinay_desiderata(data):\n",
    "    from collections import defaultdict\n",
    "    evaluation_result = defaultdict(dict)\n",
    "    for data in MRBenchv1_data:\n",
    "        data_type= data['Data']\n",
    "        # if data_type != \"MathDial\":\n",
    "        #     continue\n",
    "        for model, value in data['anno_llm_responses'].items():\n",
    "            annotation_point = value['annotation_point']\n",
    "            for k, v in annotation_point.items(): \n",
    "                if v is None:\n",
    "                    continue\n",
    "                if v == desiderata[k]:\n",
    "                    if k not in evaluation_result[model]:\n",
    "                        evaluation_result[model][k] = [0,0]\n",
    "                    evaluation_result[model][k][0] += 1\n",
    "                elif v == 2:\n",
    "                    if k not in evaluation_result[model]:\n",
    "                        evaluation_result[model][k] = [0,0]\n",
    "                    evaluation_result[model][k][0] += 0.5\n",
    "                else:\n",
    "                    if k not in evaluation_result[model] and v is not None:\n",
    "                        evaluation_result[model][k] = [0,0]\n",
    "                    evaluation_result[model][k][1] += 1\n",
    "    return evaluation_result\n",
    "\n",
    "evaluation_result = evaluate_ordinay_desiderata(MRBenchv1_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be341f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Tutor', 'Actionability', 'Coherence', 'Mistake_Identification',\n",
      "       'Mistake_Location', 'Providing_Guidance', 'Revealing_of_the_Answer',\n",
      "       'Tutor_Tone', 'humanlikeness'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "def print_evaluation_result(evaluation_result):\n",
    "    import pandas as pd\n",
    "    pd_result = []\n",
    "    columns = []\n",
    "    for model, value in evaluation_result.items():\n",
    "        model_result = []\n",
    "        value = sorted(value.items(), key=lambda x: x[0])\n",
    "        columns = [k for k, v in value]\n",
    "        for k, v in value:\n",
    "            model_result.append((v[0]/(v[0]+v[1] )* 100.0))\n",
    "        pd_result.append([model] + model_result)  \n",
    "    columns = ['Tutor'] + columns\n",
    "    pd_result = pd.DataFrame(pd_result, columns=columns)\n",
    "    print(pd_result.columns)\n",
    "    columns_mapping = {\n",
    "        'Mistake_Identification': 'Mistake_Identification',\n",
    "        'Mistake_Location': 'Mistake_Location',\n",
    "        'Revealing_of_the_Answer': 'Revealing_of_the_Answer',\n",
    "        'Providing_Guidance': 'Providing_Guidance',\n",
    "        'Actionability': 'Actionability',\n",
    "        'Coherence': 'Coherence',\n",
    "        'Tutor_Tone': 'Tutor_Tone',\n",
    "        'humanlikeness': 'Human-likeness'\n",
    "    }\n",
    "    pd_result.rename(columns=columns_mapping, inplace=True)\n",
    "    pd_result = pd_result[['Tutor', 'Mistake_Identification', 'Mistake_Location', 'Revealing_of_the_Answer', 'Providing_Guidance', 'Actionability', 'Coherence', 'Tutor_Tone', 'Human-likeness']].round(2)\n",
    "    return pd_result\n",
    "\n",
    "pd_result=print_evaluation_result(evaluation_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e108575e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tutor</th>\n",
       "      <th>Mistake_Identification</th>\n",
       "      <th>Mistake_Location</th>\n",
       "      <th>Revealing_of_the_Answer</th>\n",
       "      <th>Providing_Guidance</th>\n",
       "      <th>Actionability</th>\n",
       "      <th>Coherence</th>\n",
       "      <th>Tutor_Tone</th>\n",
       "      <th>Human-likeness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Expert</td>\n",
       "      <td>94.41</td>\n",
       "      <td>79.50</td>\n",
       "      <td>97.92</td>\n",
       "      <td>88.64</td>\n",
       "      <td>93.35</td>\n",
       "      <td>95.05</td>\n",
       "      <td>99.12</td>\n",
       "      <td>99.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Expert_paper</td>\n",
       "      <td>76.04</td>\n",
       "      <td>63.02</td>\n",
       "      <td>90.62</td>\n",
       "      <td>67.19</td>\n",
       "      <td>76.04</td>\n",
       "      <td>79.17</td>\n",
       "      <td>92.19</td>\n",
       "      <td>87.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GPT-4_paper</td>\n",
       "      <td>94.27</td>\n",
       "      <td>84.38</td>\n",
       "      <td>53.12</td>\n",
       "      <td>76.04</td>\n",
       "      <td>46.35</td>\n",
       "      <td>90.17</td>\n",
       "      <td>37.50</td>\n",
       "      <td>89.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GPT4</td>\n",
       "      <td>95.29</td>\n",
       "      <td>89.36</td>\n",
       "      <td>54.69</td>\n",
       "      <td>90.48</td>\n",
       "      <td>50.00</td>\n",
       "      <td>97.86</td>\n",
       "      <td>100.00</td>\n",
       "      <td>99.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gemini</td>\n",
       "      <td>92.00</td>\n",
       "      <td>70.49</td>\n",
       "      <td>92.71</td>\n",
       "      <td>88.27</td>\n",
       "      <td>78.22</td>\n",
       "      <td>92.31</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Tutor  Mistake_Identification  Mistake_Location  \\\n",
       "5        Expert                   94.41             79.50   \n",
       "1  Expert_paper                   76.04             63.02   \n",
       "7   GPT-4_paper                   94.27             84.38   \n",
       "6          GPT4                   95.29             89.36   \n",
       "0        Gemini                   92.00             70.49   \n",
       "\n",
       "   Revealing_of_the_Answer  Providing_Guidance  Actionability  Coherence  \\\n",
       "5                    97.92               88.64          93.35      95.05   \n",
       "1                    90.62               67.19          76.04      79.17   \n",
       "7                    53.12               76.04          46.35      90.17   \n",
       "6                    54.69               90.48          50.00      97.86   \n",
       "0                    92.71               88.27          78.22      92.31   \n",
       "\n",
       "   Tutor_Tone  Human-likeness  \n",
       "5       99.12           99.47  \n",
       "1       92.19           87.50  \n",
       "7       37.50           89.62  \n",
       "6      100.00           99.46  \n",
       "0      100.00          100.00  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "ss = pd.read_csv('../paper/paper_result.csv',sep='\\t')\n",
    "ss['Tutor'] = ss['Tutor'].apply(lambda x: x.replace(\"*\",\"\")+\"_paper\")\n",
    "concat_result = pd.concat([ss, pd_result], axis=0)\n",
    "concat_result = concat_result.sort_values(by='Tutor')\n",
    "concat_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4dc71fe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tutor</th>\n",
       "      <th>Mistake_Identification</th>\n",
       "      <th>Mistake_Location</th>\n",
       "      <th>Revealing_of_the_Answer</th>\n",
       "      <th>Providing_Guidance</th>\n",
       "      <th>Actionability</th>\n",
       "      <th>Coherence</th>\n",
       "      <th>Tutor_Tone</th>\n",
       "      <th>Human-likeness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Expert</td>\n",
       "      <td>94.41</td>\n",
       "      <td>79.50</td>\n",
       "      <td>97.92</td>\n",
       "      <td>88.64</td>\n",
       "      <td>93.35</td>\n",
       "      <td>95.05</td>\n",
       "      <td>99.12</td>\n",
       "      <td>99.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Expert_paper</td>\n",
       "      <td>76.04</td>\n",
       "      <td>63.02</td>\n",
       "      <td>90.62</td>\n",
       "      <td>67.19</td>\n",
       "      <td>76.04</td>\n",
       "      <td>79.17</td>\n",
       "      <td>92.19</td>\n",
       "      <td>87.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GPT-4_paper</td>\n",
       "      <td>94.27</td>\n",
       "      <td>84.38</td>\n",
       "      <td>53.12</td>\n",
       "      <td>76.04</td>\n",
       "      <td>46.35</td>\n",
       "      <td>90.17</td>\n",
       "      <td>37.50</td>\n",
       "      <td>89.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GPT4</td>\n",
       "      <td>95.29</td>\n",
       "      <td>89.36</td>\n",
       "      <td>54.69</td>\n",
       "      <td>90.48</td>\n",
       "      <td>50.00</td>\n",
       "      <td>97.86</td>\n",
       "      <td>100.00</td>\n",
       "      <td>99.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gemini</td>\n",
       "      <td>92.00</td>\n",
       "      <td>70.49</td>\n",
       "      <td>92.71</td>\n",
       "      <td>88.27</td>\n",
       "      <td>78.22</td>\n",
       "      <td>92.31</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gemini_paper</td>\n",
       "      <td>63.02</td>\n",
       "      <td>39.58</td>\n",
       "      <td>67.71</td>\n",
       "      <td>37.50</td>\n",
       "      <td>42.71</td>\n",
       "      <td>56.77</td>\n",
       "      <td>21.88</td>\n",
       "      <td>68.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Llama31405B</td>\n",
       "      <td>97.37</td>\n",
       "      <td>91.37</td>\n",
       "      <td>81.77</td>\n",
       "      <td>95.42</td>\n",
       "      <td>81.67</td>\n",
       "      <td>97.88</td>\n",
       "      <td>100.00</td>\n",
       "      <td>95.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Llama31405B_paper</td>\n",
       "      <td>94.27</td>\n",
       "      <td>84.38</td>\n",
       "      <td>80.73</td>\n",
       "      <td>77.08</td>\n",
       "      <td>74.48</td>\n",
       "      <td>91.67</td>\n",
       "      <td>16.15</td>\n",
       "      <td>90.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Llama318B</td>\n",
       "      <td>87.10</td>\n",
       "      <td>62.16</td>\n",
       "      <td>76.56</td>\n",
       "      <td>81.94</td>\n",
       "      <td>56.57</td>\n",
       "      <td>93.39</td>\n",
       "      <td>100.00</td>\n",
       "      <td>99.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Llama318B_paper</td>\n",
       "      <td>80.21</td>\n",
       "      <td>54.69</td>\n",
       "      <td>73.96</td>\n",
       "      <td>45.31</td>\n",
       "      <td>42.71</td>\n",
       "      <td>80.73</td>\n",
       "      <td>19.79</td>\n",
       "      <td>93.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mistral</td>\n",
       "      <td>96.82</td>\n",
       "      <td>85.08</td>\n",
       "      <td>89.06</td>\n",
       "      <td>87.10</td>\n",
       "      <td>81.27</td>\n",
       "      <td>95.14</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mistral_paper</td>\n",
       "      <td>93.23</td>\n",
       "      <td>73.44</td>\n",
       "      <td>86.46</td>\n",
       "      <td>63.54</td>\n",
       "      <td>70.31</td>\n",
       "      <td>86.98</td>\n",
       "      <td>15.10</td>\n",
       "      <td>95.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Novice</td>\n",
       "      <td>75.56</td>\n",
       "      <td>19.23</td>\n",
       "      <td>88.68</td>\n",
       "      <td>17.65</td>\n",
       "      <td>12.50</td>\n",
       "      <td>93.02</td>\n",
       "      <td>100.00</td>\n",
       "      <td>65.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Novice_paper</td>\n",
       "      <td>43.33</td>\n",
       "      <td>16.67</td>\n",
       "      <td>80.00</td>\n",
       "      <td>11.67</td>\n",
       "      <td>1.67</td>\n",
       "      <td>50.00</td>\n",
       "      <td>90.00</td>\n",
       "      <td>35.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Phi3</td>\n",
       "      <td>30.34</td>\n",
       "      <td>27.56</td>\n",
       "      <td>79.17</td>\n",
       "      <td>38.41</td>\n",
       "      <td>12.93</td>\n",
       "      <td>44.96</td>\n",
       "      <td>100.00</td>\n",
       "      <td>65.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Phi3_paper</td>\n",
       "      <td>28.65</td>\n",
       "      <td>26.04</td>\n",
       "      <td>73.96</td>\n",
       "      <td>17.71</td>\n",
       "      <td>11.98</td>\n",
       "      <td>39.58</td>\n",
       "      <td>45.31</td>\n",
       "      <td>52.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sonnet</td>\n",
       "      <td>92.49</td>\n",
       "      <td>79.78</td>\n",
       "      <td>96.88</td>\n",
       "      <td>79.37</td>\n",
       "      <td>82.99</td>\n",
       "      <td>96.25</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sonnet_paper</td>\n",
       "      <td>85.42</td>\n",
       "      <td>69.79</td>\n",
       "      <td>94.79</td>\n",
       "      <td>59.38</td>\n",
       "      <td>60.94</td>\n",
       "      <td>88.54</td>\n",
       "      <td>54.69</td>\n",
       "      <td>96.35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Tutor  Mistake_Identification  Mistake_Location  \\\n",
       "5             Expert                   94.41             79.50   \n",
       "1       Expert_paper                   76.04             63.02   \n",
       "7        GPT-4_paper                   94.27             84.38   \n",
       "6               GPT4                   95.29             89.36   \n",
       "0             Gemini                   92.00             70.49   \n",
       "4       Gemini_paper                   63.02             39.58   \n",
       "3        Llama31405B                   97.37             91.37   \n",
       "8  Llama31405B_paper                   94.27             84.38   \n",
       "2          Llama318B                   87.10             62.16   \n",
       "2    Llama318B_paper                   80.21             54.69   \n",
       "4            Mistral                   96.82             85.08   \n",
       "6      Mistral_paper                   93.23             73.44   \n",
       "8             Novice                   75.56             19.23   \n",
       "0       Novice_paper                   43.33             16.67   \n",
       "1               Phi3                   30.34             27.56   \n",
       "3         Phi3_paper                   28.65             26.04   \n",
       "7             Sonnet                   92.49             79.78   \n",
       "5       Sonnet_paper                   85.42             69.79   \n",
       "\n",
       "   Revealing_of_the_Answer  Providing_Guidance  Actionability  Coherence  \\\n",
       "5                    97.92               88.64          93.35      95.05   \n",
       "1                    90.62               67.19          76.04      79.17   \n",
       "7                    53.12               76.04          46.35      90.17   \n",
       "6                    54.69               90.48          50.00      97.86   \n",
       "0                    92.71               88.27          78.22      92.31   \n",
       "4                    67.71               37.50          42.71      56.77   \n",
       "3                    81.77               95.42          81.67      97.88   \n",
       "8                    80.73               77.08          74.48      91.67   \n",
       "2                    76.56               81.94          56.57      93.39   \n",
       "2                    73.96               45.31          42.71      80.73   \n",
       "4                    89.06               87.10          81.27      95.14   \n",
       "6                    86.46               63.54          70.31      86.98   \n",
       "8                    88.68               17.65          12.50      93.02   \n",
       "0                    80.00               11.67           1.67      50.00   \n",
       "1                    79.17               38.41          12.93      44.96   \n",
       "3                    73.96               17.71          11.98      39.58   \n",
       "7                    96.88               79.37          82.99      96.25   \n",
       "5                    94.79               59.38          60.94      88.54   \n",
       "\n",
       "   Tutor_Tone  Human-likeness  \n",
       "5       99.12           99.47  \n",
       "1       92.19           87.50  \n",
       "7       37.50           89.62  \n",
       "6      100.00           99.46  \n",
       "0      100.00          100.00  \n",
       "4       21.88           68.23  \n",
       "3      100.00           95.26  \n",
       "8       16.15           90.62  \n",
       "2      100.00           99.47  \n",
       "2       19.79           93.75  \n",
       "4      100.00          100.00  \n",
       "6       15.10           95.31  \n",
       "8      100.00           65.91  \n",
       "0       90.00           35.00  \n",
       "1      100.00           65.44  \n",
       "3       45.31           52.08  \n",
       "7      100.00          100.00  \n",
       "5       54.69           96.35  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732411b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
